{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Test Analysis: Website Checkout Button Redesign\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This notebook analyzes an A/B test comparing two checkout button designs for an e-commerce website. We'll determine whether the new design (Version B) significantly improves conversion rates compared to the current design (Version A).\n",
    "\n",
    "**Business Question:** Should we roll out the new checkout button design to all users?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Generation\n",
    "\n",
    "First, let's import our libraries and create realistic test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Test Data\n",
    "\n",
    "We'll simulate a 2-week A/B test with:\n",
    "- **Control Group (A):** Current green \"Checkout\" button - 12% baseline conversion\n",
    "- **Treatment Group (B):** New orange \"Complete Purchase\" button - 14.5% conversion (hypothesized improvement)\n",
    "- **Sample Size:** 5,000 users per group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parameters\n",
    "n_control = 5000\n",
    "n_treatment = 5000\n",
    "control_conversion_rate = 0.12\n",
    "treatment_conversion_rate = 0.145\n",
    "\n",
    "# Generate conversion data (1 = converted, 0 = did not convert)\n",
    "control_conversions = np.random.binomial(1, control_conversion_rate, n_control)\n",
    "treatment_conversions = np.random.binomial(1, treatment_conversion_rate, n_treatment)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'user_id': range(1, n_control + n_treatment + 1),\n",
    "    'group': ['Control'] * n_control + ['Treatment'] * n_treatment,\n",
    "    'converted': np.concatenate([control_conversions, treatment_conversions])\n",
    "})\n",
    "\n",
    "# Preview data\n",
    "print(\"Dataset Preview:\")\n",
    "print(df.head(10))\n",
    "print(f\"\\nTotal Users: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "Let's first understand our data before diving into statistical tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate conversion rates by group\n",
    "conversion_summary = df.groupby('group').agg({\n",
    "    'converted': ['sum', 'count', 'mean']\n",
    "}).round(4)\n",
    "\n",
    "conversion_summary.columns = ['Conversions', 'Total_Users', 'Conversion_Rate']\n",
    "conversion_summary['Conversion_Rate_Pct'] = (conversion_summary['Conversion_Rate'] * 100).round(2)\n",
    "\n",
    "print(\"Conversion Summary by Group:\")\n",
    "print(conversion_summary)\n",
    "\n",
    "# Calculate absolute and relative lift\n",
    "control_rate = conversion_summary.loc['Control', 'Conversion_Rate']\n",
    "treatment_rate = conversion_summary.loc['Treatment', 'Conversion_Rate']\n",
    "\n",
    "absolute_lift = treatment_rate - control_rate\n",
    "relative_lift = (treatment_rate / control_rate - 1) * 100\n",
    "\n",
    "print(f\"\\nüìä Key Metrics:\")\n",
    "print(f\"Control Rate: {control_rate:.2%}\")\n",
    "print(f\"Treatment Rate: {treatment_rate:.2%}\")\n",
    "print(f\"Absolute Lift: {absolute_lift:.2%}\")\n",
    "print(f\"Relative Lift: {relative_lift:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart of conversion rates\n",
    "ax1 = axes[0]\n",
    "rates = [control_rate * 100, treatment_rate * 100]\n",
    "groups = ['Control\\n(Current Button)', 'Treatment\\n(New Button)']\n",
    "colors = ['#3498db', '#e74c3c']\n",
    "\n",
    "bars = ax1.bar(groups, rates, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax1.set_ylabel('Conversion Rate (%)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Conversion Rate by Group', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim(0, max(rates) * 1.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, rate in zip(bars, rates):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{rate:.2f}%',\n",
    "             ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Stacked bar chart showing conversions vs non-conversions\n",
    "ax2 = axes[1]\n",
    "summary_data = df.groupby(['group', 'converted']).size().unstack(fill_value=0)\n",
    "summary_pct = summary_data.div(summary_data.sum(axis=1), axis=0) * 100\n",
    "\n",
    "summary_pct.plot(kind='bar', stacked=True, ax=ax2, \n",
    "                 color=['#95a5a6', '#27ae60'], alpha=0.8, edgecolor='black')\n",
    "ax2.set_ylabel('Percentage of Users (%)', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('')\n",
    "ax2.set_title('Conversion Breakdown by Group', fontsize=14, fontweight='bold')\n",
    "ax2.legend(['Did Not Convert', 'Converted'], loc='upper right')\n",
    "ax2.set_xticklabels(['Control', 'Treatment'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Hypothesis Testing\n",
    "\n",
    "### Setting Up Our Hypotheses\n",
    "\n",
    "Before we run the test, let's clearly state what we're testing:\n",
    "\n",
    "**Null Hypothesis (H‚ÇÄ):** There is no difference in conversion rates between Control and Treatment.  \n",
    "- Mathematically: `p_control = p_treatment`\n",
    "\n",
    "**Alternative Hypothesis (H‚ÇÅ):** The Treatment group has a different conversion rate than Control.  \n",
    "- Mathematically: `p_control ‚â† p_treatment`\n",
    "\n",
    "**Significance Level (Œ±):** 0.05 (5%)  \n",
    "- This means we need 95% confidence to reject the null hypothesis\n",
    "\n",
    "### Why a Two-Proportion Z-Test?\n",
    "\n",
    "We're comparing conversion rates (proportions) between two independent groups. The two-proportion z-test is the appropriate statistical test for this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for statistical test\n",
    "control_conv = control_conversions.sum()\n",
    "control_n = len(control_conversions)\n",
    "treatment_conv = treatment_conversions.sum()\n",
    "treatment_n = len(treatment_conversions)\n",
    "\n",
    "# Calculate pooled proportion (used in z-test)\n",
    "pooled_prob = (control_conv + treatment_conv) / (control_n + treatment_n)\n",
    "pooled_se = np.sqrt(pooled_prob * (1 - pooled_prob) * (1/control_n + 1/treatment_n))\n",
    "\n",
    "# Calculate z-statistic\n",
    "z_stat = (treatment_rate - control_rate) / pooled_se\n",
    "\n",
    "# Calculate p-value (two-tailed test)\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TWO-PROPORTION Z-TEST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nControl Group:\")\n",
    "print(f\"  Conversions: {control_conv:,} out of {control_n:,} ({control_rate:.2%})\")\n",
    "print(f\"\\nTreatment Group:\")\n",
    "print(f\"  Conversions: {treatment_conv:,} out of {treatment_n:,} ({treatment_rate:.2%})\")\n",
    "print(f\"\\nTest Statistics:\")\n",
    "print(f\"  Z-statistic: {z_stat:.4f}\")\n",
    "print(f\"  P-value: {p_value:.4f}\")\n",
    "print(f\"  Significance level (Œ±): 0.05\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Two-Sample T-Test\n",
    "\n",
    "We can also verify our results using a t-test (appropriate for comparing means of binary data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform two-sample t-test\n",
    "t_stat, t_pvalue = stats.ttest_ind(treatment_conversions, control_conversions)\n",
    "\n",
    "print(\"TWO-SAMPLE T-TEST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {t_pvalue:.4f}\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNote: Both tests should yield similar conclusions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Confidence Intervals\n",
    "\n",
    "Confidence intervals tell us the **range of plausible values** for the true conversion rate difference. A 95% confidence interval means: \"If we ran this experiment 100 times, we'd expect the true difference to fall within this range 95 times.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ci(successes, n, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Calculate confidence interval for a proportion using normal approximation.\n",
    "    \"\"\"\n",
    "    prop = successes / n\n",
    "    z_critical = stats.norm.ppf(1 - (1 - confidence) / 2)\n",
    "    se = np.sqrt(prop * (1 - prop) / n)\n",
    "    margin = z_critical * se\n",
    "    return prop - margin, prop + margin\n",
    "\n",
    "# Calculate 95% confidence intervals for each group\n",
    "control_ci = calculate_ci(control_conv, control_n)\n",
    "treatment_ci = calculate_ci(treatment_conv, treatment_n)\n",
    "\n",
    "# Calculate confidence interval for the DIFFERENCE in conversion rates\n",
    "diff = treatment_rate - control_rate\n",
    "se_diff = np.sqrt((control_rate * (1 - control_rate) / control_n) + \n",
    "                  (treatment_rate * (1 - treatment_rate) / treatment_n))\n",
    "z_critical = 1.96  # For 95% confidence\n",
    "diff_ci = (diff - z_critical * se_diff, diff + z_critical * se_diff)\n",
    "\n",
    "print(\"95% CONFIDENCE INTERVALS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nControl Group Conversion Rate:\")\n",
    "print(f\"  Point Estimate: {control_rate:.2%}\")\n",
    "print(f\"  95% CI: [{control_ci[0]:.2%}, {control_ci[1]:.2%}]\")\n",
    "\n",
    "print(f\"\\nTreatment Group Conversion Rate:\")\n",
    "print(f\"  Point Estimate: {treatment_rate:.2%}\")\n",
    "print(f\"  95% CI: [{treatment_ci[0]:.2%}, {treatment_ci[1]:.2%}]\")\n",
    "\n",
    "print(f\"\\nDifference (Treatment - Control):\")\n",
    "print(f\"  Point Estimate: {diff:.2%}\")\n",
    "print(f\"  95% CI: [{diff_ci[0]:.2%}, {diff_ci[1]:.2%}]\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confidence intervals\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Data for plotting\n",
    "groups = ['Control', 'Treatment']\n",
    "estimates = [control_rate * 100, treatment_rate * 100]\n",
    "ci_lower = [control_ci[0] * 100, treatment_ci[0] * 100]\n",
    "ci_upper = [control_ci[1] * 100, treatment_ci[1] * 100]\n",
    "errors_lower = [estimates[i] - ci_lower[i] for i in range(2)]\n",
    "errors_upper = [ci_upper[i] - estimates[i] for i in range(2)]\n",
    "\n",
    "# Create error bars\n",
    "ax.errorbar(groups, estimates, \n",
    "            yerr=[errors_lower, errors_upper],\n",
    "            fmt='o', markersize=12, capsize=10, capthick=2,\n",
    "            linewidth=2, color='#2c3e50', ecolor='#34495e')\n",
    "\n",
    "# Add point estimates as text\n",
    "for i, (group, est) in enumerate(zip(groups, estimates)):\n",
    "    ax.text(i, est + 0.3, f'{est:.2f}%', \n",
    "            ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Conversion Rate (%)', fontsize=13, fontweight='bold')\n",
    "ax.set_title('95% Confidence Intervals for Conversion Rates', \n",
    "             fontsize=15, fontweight='bold', pad=20)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim(10, 16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Insight:\")\n",
    "if diff_ci[0] > 0:\n",
    "    print(\"The confidence interval for the difference does NOT include zero.\")\n",
    "    print(\"This means we can be 95% confident that Treatment truly outperforms Control.\")\n",
    "else:\n",
    "    print(\"The confidence interval for the difference includes zero.\")\n",
    "    print(\"This means we cannot rule out that there's no real difference between groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Statistical Significance Interpretation\n",
    "\n",
    "Let's interpret our p-value in plain English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STATISTICAL SIGNIFICANCE INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nP-value: {p_value:.4f}\")\n",
    "print(f\"Significance level (Œ±): {alpha}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f\"\\n‚úÖ RESULT: Statistically Significant (p < {alpha})\")\n",
    "    print(\"\\nüìä What this means in plain English:\")\n",
    "    print(f\"   If there were truly NO difference between the buttons, we would\")\n",
    "    print(f\"   see a difference this large or larger only {p_value*100:.2f}% of the time\")\n",
    "    print(f\"   due to random chance alone.\")\n",
    "    print(f\"\\n   Since this is less than our {alpha*100:.0f}% threshold, we have strong\")\n",
    "    print(f\"   evidence that the new button design genuinely improves conversions.\")\n",
    "    print(f\"\\nüéØ Recommendation: REJECT the null hypothesis.\")\n",
    "    print(f\"   The Treatment button appears to be genuinely better.\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå RESULT: Not Statistically Significant (p >= {alpha})\")\n",
    "    print(\"\\nüìä What this means in plain English:\")\n",
    "    print(f\"   If there were truly NO difference between the buttons, we would\")\n",
    "    print(f\"   see a difference this large or larger {p_value*100:.2f}% of the time\")\n",
    "    print(f\"   due to random chance alone.\")\n",
    "    print(f\"\\n   Since this exceeds our {alpha*100:.0f}% threshold, we don't have enough\")\n",
    "    print(f\"   evidence to conclude the new button is better.\")\n",
    "    print(f\"\\nüéØ Recommendation: FAIL TO REJECT the null hypothesis.\")\n",
    "    print(f\"   We cannot confidently say the Treatment button is better.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Effect Size & Practical Significance\n",
    "\n",
    "**Statistical significance ‚â† Practical significance**\n",
    "\n",
    "Even if our test is statistically significant, we need to ask: \"Is this difference large enough to matter in the real world?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate effect size (Cohen's h for proportions)\n",
    "def cohens_h(p1, p2):\n",
    "    \"\"\"\n",
    "    Calculate Cohen's h effect size for two proportions.\n",
    "    Small effect: h = 0.2\n",
    "    Medium effect: h = 0.5\n",
    "    Large effect: h = 0.8\n",
    "    \"\"\"\n",
    "    return 2 * (np.arcsin(np.sqrt(p1)) - np.arcsin(np.sqrt(p2)))\n",
    "\n",
    "effect_size = abs(cohens_h(treatment_rate, control_rate))\n",
    "\n",
    "# Determine effect size category\n",
    "if effect_size < 0.2:\n",
    "    effect_category = \"Small\"\n",
    "elif effect_size < 0.5:\n",
    "    effect_category = \"Medium\"\n",
    "else:\n",
    "    effect_category = \"Large\"\n",
    "\n",
    "print(\"EFFECT SIZE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nCohen's h: {effect_size:.4f} ({effect_category} effect)\")\n",
    "print(f\"\\nAbsolute difference: {absolute_lift:.2%}\")\n",
    "print(f\"Relative lift: {relative_lift:.2f}%\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business impact calculation\n",
    "print(\"\\nüí∞ BUSINESS IMPACT PROJECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Hypothetical business metrics\n",
    "monthly_visitors = 100000\n",
    "avg_order_value = 75\n",
    "\n",
    "# Current state\n",
    "current_monthly_conversions = monthly_visitors * control_rate\n",
    "current_monthly_revenue = current_monthly_conversions * avg_order_value\n",
    "\n",
    "# Projected state with new button\n",
    "projected_monthly_conversions = monthly_visitors * treatment_rate\n",
    "projected_monthly_revenue = projected_monthly_conversions * avg_order_value\n",
    "\n",
    "# Incremental impact\n",
    "additional_conversions = projected_monthly_conversions - current_monthly_conversions\n",
    "additional_revenue = projected_monthly_revenue - current_monthly_revenue\n",
    "\n",
    "print(f\"\\nAssumptions:\")\n",
    "print(f\"  ‚Ä¢ Monthly website visitors: {monthly_visitors:,}\")\n",
    "print(f\"  ‚Ä¢ Average order value: ${avg_order_value:.2f}\")\n",
    "\n",
    "print(f\"\\nCurrent Performance (Control):\")\n",
    "print(f\"  ‚Ä¢ Conversions/month: {current_monthly_conversions:,.0f}\")\n",
    "print(f\"  ‚Ä¢ Revenue/month: ${current_monthly_revenue:,.2f}\")\n",
    "\n",
    "print(f\"\\nProjected Performance (Treatment):\")\n",
    "print(f\"  ‚Ä¢ Conversions/month: {projected_monthly_conversions:,.0f}\")\n",
    "print(f\"  ‚Ä¢ Revenue/month: ${projected_monthly_revenue:,.2f}\")\n",
    "\n",
    "print(f\"\\nüìà Incremental Impact:\")\n",
    "print(f\"  ‚Ä¢ Additional conversions/month: {additional_conversions:,.0f}\")\n",
    "print(f\"  ‚Ä¢ Additional revenue/month: ${additional_revenue:,.2f}\")\n",
    "print(f\"  ‚Ä¢ Additional revenue/year: ${additional_revenue * 12:,.2f}\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Power Analysis & Sample Size\n",
    "\n",
    "**Statistical Power** is the probability of detecting a real effect when it exists. Typically, we want at least 80% power.\n",
    "\n",
    "Let's check if our test had adequate power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import zt_ind_solve_power\n",
    "from statsmodels.stats.proportion import proportion_effectsize\n",
    "\n",
    "# Calculate effect size\n",
    "effect_size_power = proportion_effectsize(control_rate, treatment_rate)\n",
    "\n",
    "# Calculate achieved power\n",
    "achieved_power = zt_ind_solve_power(effect_size=effect_size_power,\n",
    "                                    nobs1=control_n,\n",
    "                                    alpha=0.05,\n",
    "                                    ratio=treatment_n/control_n,\n",
    "                                    alternative='two-sided')\n",
    "\n",
    "# Calculate required sample size for 80% power\n",
    "required_n = zt_ind_solve_power(effect_size=effect_size_power,\n",
    "                                power=0.8,\n",
    "                                alpha=0.05,\n",
    "                                ratio=1.0,\n",
    "                                alternative='two-sided')\n",
    "\n",
    "print(\"STATISTICAL POWER ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nActual sample size per group: {control_n:,}\")\n",
    "print(f\"Achieved statistical power: {achieved_power:.2%}\")\n",
    "print(f\"\\nRequired sample size for 80% power: {required_n:,.0f} per group\")\n",
    "\n",
    "if achieved_power >= 0.8:\n",
    "    print(f\"\\n‚úÖ Our test had sufficient power to detect this effect.\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Our test was underpowered. Consider collecting more data.\")\n",
    "    \n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Conclusion & Recommendations\n",
    "\n",
    "### Summary of Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \" * 20 + \"FINAL DECISION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä Test Results:\")\n",
    "print(f\"   ‚Ä¢ Control conversion rate: {control_rate:.2%}\")\n",
    "print(f\"   ‚Ä¢ Treatment conversion rate: {treatment_rate:.2%}\")\n",
    "print(f\"   ‚Ä¢ Absolute improvement: {absolute_lift:.2%}\")\n",
    "print(f\"   ‚Ä¢ Relative improvement: {relative_lift:.1f}%\")\n",
    "\n",
    "print(f\"\\nüìà Statistical Analysis:\")\n",
    "print(f\"   ‚Ä¢ P-value: {p_value:.4f}\")\n",
    "print(f\"   ‚Ä¢ Result: {'Statistically significant' if p_value < 0.05 else 'Not statistically significant'}\")\n",
    "print(f\"   ‚Ä¢ 95% CI for difference: [{diff_ci[0]:.2%}, {diff_ci[1]:.2%}]\")\n",
    "print(f\"   ‚Ä¢ Effect size: {effect_category} (Cohen's h = {effect_size:.3f})\")\n",
    "print(f\"   ‚Ä¢ Statistical power: {achieved_power:.1%}\")\n",
    "\n",
    "print(f\"\\nüí∞ Business Impact:\")\n",
    "print(f\"   ‚Ä¢ Additional monthly revenue: ${additional_revenue:,.2f}\")\n",
    "print(f\"   ‚Ä¢ Projected annual revenue lift: ${additional_revenue * 12:,.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüéØ FINAL RECOMMENDATION:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if p_value < 0.05 and diff_ci[0] > 0:\n",
    "    print(\"\\n‚úÖ PROCEED WITH ROLLOUT\")\n",
    "    print(\"\\nThe new checkout button design shows statistically significant\")\n",
    "    print(\"improvement over the current design. Based on our analysis:\")\n",
    "    print(\"\\n  1. The treatment group converted at a significantly higher rate\")\n",
    "    print(f\"  2. We're 95% confident the true improvement is between\")\n",
    "    print(f\"     {diff_ci[0]:.2%} and {diff_ci[1]:.2%}\")\n",
    "    print(f\"  3. The projected annual revenue impact is ${additional_revenue * 12:,.2f}\")\n",
    "    print(\"\\n  Recommendation: Roll out the new button design to all users.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  DO NOT PROCEED - INSUFFICIENT EVIDENCE\")\n",
    "    print(\"\\nWhile the treatment group showed higher conversion rates,\")\n",
    "    print(\"the difference is not statistically significant. This means:\")\n",
    "    print(\"\\n  1. We cannot rule out random chance as the cause\")\n",
    "    print(\"  2. The observed difference might disappear with more data\")\n",
    "    print(\"\\n  Options:\")\n",
    "    print(\"    ‚Ä¢ Extend the test to collect more data\")\n",
    "    print(\"    ‚Ä¢ Test a more dramatic design change\")\n",
    "    print(\"    ‚Ä¢ Keep the current design\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Key Learnings & Next Steps\n",
    "\n",
    "### What We Learned About A/B Testing\n",
    "\n",
    "1. **Statistical Significance vs. Practical Significance**  \n",
    "   A result can be statistically significant but too small to matter in business terms (or vice versa in small samples).\n",
    "\n",
    "2. **The Role of Sample Size**  \n",
    "   Larger samples give us more confidence and allow us to detect smaller effects.\n",
    "\n",
    "3. **P-values Tell One Part of the Story**  \n",
    "   Always combine p-values with confidence intervals and effect sizes for complete understanding.\n",
    "\n",
    "4. **Business Context Matters**  \n",
    "   Even a small percentage improvement can translate to significant revenue at scale.\n",
    "\n",
    "### Potential Next Steps\n",
    "\n",
    "- **Segment Analysis:** Do results differ by user type, device, or traffic source?\n",
    "- **Long-term Monitoring:** Continue tracking to ensure results hold over time\n",
    "- **Additional Tests:** Test other elements (copy, color, placement)\n",
    "- **Multi-variate Testing:** Test multiple changes simultaneously\n",
    "\n",
    "---\n",
    "\n",
    "## Appendix: Statistical Formulas Used\n",
    "\n",
    "### Two-Proportion Z-Test\n",
    "$$z = \\frac{\\hat{p}_2 - \\hat{p}_1}{\\sqrt{\\hat{p}(1-\\hat{p})(\\frac{1}{n_1} + \\frac{1}{n_2})}}$$\n",
    "\n",
    "where $\\hat{p} = \\frac{x_1 + x_2}{n_1 + n_2}$ (pooled proportion)\n",
    "\n",
    "### Confidence Interval for Proportion\n",
    "$$CI = \\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$$\n",
    "\n",
    "### Cohen's h (Effect Size for Proportions)\n",
    "$$h = 2(\\arcsin(\\sqrt{p_1}) - \\arcsin(\\sqrt{p_2}))$$\n",
    "\n",
    "---\n",
    "\n",
    "*End of Analysis*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
