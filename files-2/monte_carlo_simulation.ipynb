{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Simulation for A/B Testing\n",
    "\n",
    "## What is Monte Carlo Simulation?\n",
    "\n",
    "Instead of running our A/B test once, we'll simulate it **10,000 times** to understand:\n",
    "- How often would we get these results by random chance?\n",
    "- What's the range of possible outcomes?\n",
    "- How confident should we be in our decision?\n",
    "\n",
    "**Think of it like this:** Instead of flipping a coin once, we flip it 10,000 times to truly understand the probability.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simulate A Single A/B Test\n",
    "\n",
    "First, let's create a function that runs one A/B test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_ab_test(control_rate, treatment_rate, n_per_group):\n",
    "    \"\"\"\n",
    "    Simulate a single A/B test.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with conversion rates, lift, and p-value\n",
    "    \"\"\"\n",
    "    # Generate conversions\n",
    "    control_conversions = np.random.binomial(1, control_rate, n_per_group)\n",
    "    treatment_conversions = np.random.binomial(1, treatment_rate, n_per_group)\n",
    "    \n",
    "    # Calculate rates\n",
    "    control_observed = control_conversions.mean()\n",
    "    treatment_observed = treatment_conversions.mean()\n",
    "    lift = treatment_observed - control_observed\n",
    "    \n",
    "    # Statistical test\n",
    "    t_stat, p_value = stats.ttest_ind(treatment_conversions, control_conversions)\n",
    "    \n",
    "    return {\n",
    "        'control_rate': control_observed,\n",
    "        'treatment_rate': treatment_observed,\n",
    "        'lift': lift,\n",
    "        'relative_lift': (treatment_observed / control_observed - 1) if control_observed > 0 else 0,\n",
    "        'p_value': p_value,\n",
    "        'significant': p_value < 0.05\n",
    "    }\n",
    "\n",
    "# Test it once\n",
    "single_test = run_single_ab_test(\n",
    "    control_rate=0.12,\n",
    "    treatment_rate=0.145,\n",
    "    n_per_group=5000\n",
    ")\n",
    "\n",
    "print(\"Single Test Result:\")\n",
    "print(f\"Control Rate: {single_test['control_rate']:.2%}\")\n",
    "print(f\"Treatment Rate: {single_test['treatment_rate']:.2%}\")\n",
    "print(f\"Lift: {single_test['lift']:.2%}\")\n",
    "print(f\"P-value: {single_test['p_value']:.4f}\")\n",
    "print(f\"Significant: {single_test['significant']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run 10,000 Simulations\n",
    "\n",
    "Now let's run this test 10,000 times to see the **distribution of possible outcomes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_monte_carlo_simulation(control_rate, treatment_rate, n_per_group, n_simulations=10000):\n",
    "    \"\"\"\n",
    "    Run multiple A/B test simulations.\n",
    "    \n",
    "    This answers: \"If we ran this test many times, what would we see?\"\n",
    "    \"\"\"\n",
    "    print(f\"Running {n_simulations:,} simulations...\")\n",
    "    print(f\"Each simulation: {n_per_group:,} users per group\\n\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(n_simulations):\n",
    "        if (i + 1) % 2000 == 0:\n",
    "            print(f\"  Progress: {i+1:,}/{n_simulations:,} ({(i+1)/n_simulations*100:.0f}%)\")\n",
    "        \n",
    "        result = run_single_ab_test(control_rate, treatment_rate, n_per_group)\n",
    "        results.append(result)\n",
    "    \n",
    "    print(\"\\n‚úÖ Simulation complete!\\n\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run simulations\n",
    "simulations = run_monte_carlo_simulation(\n",
    "    control_rate=0.12,\n",
    "    treatment_rate=0.145,\n",
    "    n_per_group=5000,\n",
    "    n_simulations=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Simulation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \" * 20 + \"SIMULATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nüìä CONVERSION RATE DISTRIBUTIONS:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\\nControl Group:\")\n",
    "print(f\"  Mean: {simulations['control_rate'].mean():.2%}\")\n",
    "print(f\"  Std Dev: {simulations['control_rate'].std():.2%}\")\n",
    "print(f\"  Range: [{simulations['control_rate'].min():.2%}, {simulations['control_rate'].max():.2%}]\")\n",
    "\n",
    "print(\"\\nTreatment Group:\")\n",
    "print(f\"  Mean: {simulations['treatment_rate'].mean():.2%}\")\n",
    "print(f\"  Std Dev: {simulations['treatment_rate'].std():.2%}\")\n",
    "print(f\"  Range: [{simulations['treatment_rate'].min():.2%}, {simulations['treatment_rate'].max():.2%}]\")\n",
    "\n",
    "print(\"\\nüìà LIFT ANALYSIS:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Mean Lift: {simulations['lift'].mean():.2%}\")\n",
    "print(f\"  Std Dev: {simulations['lift'].std():.2%}\")\n",
    "print(f\"  Median Lift: {simulations['lift'].median():.2%}\")\n",
    "print(f\"  5th Percentile: {simulations['lift'].quantile(0.05):.2%}\")\n",
    "print(f\"  95th Percentile: {simulations['lift'].quantile(0.95):.2%}\")\n",
    "\n",
    "# Probability of positive lift\n",
    "prob_positive = (simulations['lift'] > 0).mean()\n",
    "print(f\"\\n  Probability of ANY positive lift: {prob_positive:.1%}\")\n",
    "\n",
    "# Probability of meaningful lift (>1%)\n",
    "prob_meaningful = (simulations['lift'] > 0.01).mean()\n",
    "print(f\"  Probability of >1% lift: {prob_meaningful:.1%}\")\n",
    "\n",
    "# Statistical significance\n",
    "prob_significant = simulations['significant'].mean()\n",
    "print(f\"\\nüéØ STATISTICAL SIGNIFICANCE:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Tests achieving p < 0.05: {prob_significant:.1%}\")\n",
    "print(f\"  This is our 'statistical power': {prob_significant:.1%}\")\n",
    "\n",
    "if prob_significant >= 0.8:\n",
    "    print(f\"  ‚úÖ Excellent! We have high power to detect this effect.\")\n",
    "elif prob_significant >= 0.6:\n",
    "    print(f\"  ‚ö†Ô∏è  Moderate power. Consider increasing sample size.\")\n",
    "else:\n",
    "    print(f\"  ‚ùå Low power. We need more data to reliably detect this effect.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize the Distribution of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Distribution of Control Rates\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.hist(simulations['control_rate'] * 100, bins=50, color='#3498db', \n",
    "         alpha=0.7, edgecolor='black')\n",
    "ax1.axvline(x=12, color='red', linestyle='--', linewidth=2, label='True Rate (12%)')\n",
    "ax1.set_xlabel('Conversion Rate (%)', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Distribution of Control Group Rates', fontsize=13, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Distribution of Treatment Rates\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.hist(simulations['treatment_rate'] * 100, bins=50, color='#e74c3c', \n",
    "         alpha=0.7, edgecolor='black')\n",
    "ax2.axvline(x=14.5, color='red', linestyle='--', linewidth=2, label='True Rate (14.5%)')\n",
    "ax2.set_xlabel('Conversion Rate (%)', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Distribution of Treatment Group Rates', fontsize=13, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Distribution of Lift\n",
    "ax3 = fig.add_subplot(gs[1, :])\n",
    "ax3.hist(simulations['lift'] * 100, bins=60, color='#2ecc71', \n",
    "         alpha=0.7, edgecolor='black')\n",
    "ax3.axvline(x=2.5, color='red', linestyle='--', linewidth=2, label='True Lift (2.5%)')\n",
    "ax3.axvline(x=0, color='black', linestyle='-', linewidth=2, alpha=0.5)\n",
    "ax3.set_xlabel('Lift (%)', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Distribution of Treatment Lift (10,000 Simulations)', fontsize=13, fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add percentile markers\n",
    "p5 = simulations['lift'].quantile(0.05) * 100\n",
    "p95 = simulations['lift'].quantile(0.95) * 100\n",
    "ax3.axvline(x=p5, color='orange', linestyle=':', linewidth=2, alpha=0.7, label=f'5th-95th Percentile')\n",
    "ax3.axvline(x=p95, color='orange', linestyle=':', linewidth=2, alpha=0.7)\n",
    "ax3.legend()\n",
    "\n",
    "# 4. P-value Distribution\n",
    "ax4 = fig.add_subplot(gs[2, 0])\n",
    "ax4.hist(simulations['p_value'], bins=50, color='#9b59b6', \n",
    "         alpha=0.7, edgecolor='black')\n",
    "ax4.axvline(x=0.05, color='red', linestyle='--', linewidth=2, label='Significance Threshold (0.05)')\n",
    "ax4.set_xlabel('P-value', fontsize=11, fontweight='bold')\n",
    "ax4.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax4.set_title('Distribution of P-values', fontsize=13, fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 5. Significance Pie Chart\n",
    "ax5 = fig.add_subplot(gs[2, 1])\n",
    "sig_counts = simulations['significant'].value_counts()\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "labels = [f'Significant\\n({sig_counts[True]:,} tests)', \n",
    "          f'Not Significant\\n({sig_counts[False]:,} tests)']\n",
    "ax5.pie([sig_counts[True], sig_counts[False]], labels=labels, autopct='%1.1f%%',\n",
    "        colors=colors, startangle=90, textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
    "ax5.set_title('Statistical Significance Rate', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Monte Carlo Simulation Results: 10,000 A/B Tests', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Confidence Intervals from Simulation\n",
    "\n",
    "Monte Carlo gives us another way to calculate confidence intervals - just take percentiles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \" * 15 + \"SIMULATION-BASED CONFIDENCE INTERVALS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 95% CI for lift\n",
    "ci_lower = simulations['lift'].quantile(0.025)\n",
    "ci_upper = simulations['lift'].quantile(0.975)\n",
    "\n",
    "print(\"\\n95% Confidence Interval for Lift:\")\n",
    "print(f\"  [{ci_lower:.2%}, {ci_upper:.2%}]\")\n",
    "\n",
    "# 90% CI for lift\n",
    "ci_90_lower = simulations['lift'].quantile(0.05)\n",
    "ci_90_upper = simulations['lift'].quantile(0.95)\n",
    "\n",
    "print(\"\\n90% Confidence Interval for Lift:\")\n",
    "print(f\"  [{ci_90_lower:.2%}, {ci_90_upper:.2%}]\")\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\nüí° What This Means:\")\n",
    "print(\"-\" * 70)\n",
    "if ci_lower > 0:\n",
    "    print(\"  ‚úÖ We're 95% confident the treatment INCREASES conversions\")\n",
    "    print(f\"     The true lift is likely between {ci_lower:.2%} and {ci_upper:.2%}\")\n",
    "elif ci_upper < 0:\n",
    "    print(\"  ‚ùå We're 95% confident the treatment DECREASES conversions\")\n",
    "    print(f\"     The true lift is likely between {ci_lower:.2%} and {ci_upper:.2%}\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  The confidence interval includes zero\")\n",
    "    print(\"     We can't be confident there's any real effect\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Risk Analysis\n",
    "\n",
    "Monte Carlo helps us quantify **risk**: What's the probability of making a wrong decision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \" * 25 + \"RISK ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Risk scenarios\n",
    "print(\"\\nüé≤ PROBABILITY OF DIFFERENT OUTCOMES:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "scenarios = [\n",
    "    (\"Lift > 3%\", simulations['lift'] > 0.03),\n",
    "    (\"Lift > 2%\", simulations['lift'] > 0.02),\n",
    "    (\"Lift > 1%\", simulations['lift'] > 0.01),\n",
    "    (\"Any positive lift\", simulations['lift'] > 0),\n",
    "    (\"Negative lift\", simulations['lift'] < 0),\n",
    "    (\"Lift < -1%\", simulations['lift'] < -0.01),\n",
    "]\n",
    "\n",
    "for scenario_name, condition in scenarios:\n",
    "    probability = condition.mean()\n",
    "    print(f\"  {scenario_name:.<30} {probability:>6.1%}\")\n",
    "\n",
    "# Decision risk\n",
    "print(\"\\n\\n‚ö†Ô∏è  DECISION RISKS:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Type I Error (False Positive)\n",
    "# If there's truly NO effect, how often would we incorrectly say there is?\n",
    "print(\"\\nType I Error (False Positive Risk):\")\n",
    "print(\"  If we run this test with NO real effect, we'd still get\")\n",
    "print(\"  a 'significant' result ~5% of the time (our alpha level)\")\n",
    "\n",
    "# Type II Error (False Negative)\n",
    "false_negative_rate = (simulations['significant'] == False).mean()\n",
    "print(\"\\nType II Error (False Negative Risk):\")\n",
    "print(f\"  Even with a REAL effect, we fail to detect it {false_negative_rate:.1%} of the time\")\n",
    "print(f\"  This means our statistical power is {1-false_negative_rate:.1%}\")\n",
    "\n",
    "# Business risk\n",
    "prob_loss = (simulations['lift'] < 0).mean()\n",
    "avg_loss_when_negative = simulations[simulations['lift'] < 0]['lift'].mean()\n",
    "\n",
    "print(\"\\nüí∞ BUSINESS RISK:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Probability treatment HURTS conversions: {prob_loss:.1%}\")\n",
    "if prob_loss > 0:\n",
    "    print(f\"  Average loss when negative: {avg_loss_when_negative:.2%}\")\n",
    "    \n",
    "    # Expected value calculation\n",
    "    expected_lift = simulations['lift'].mean()\n",
    "    print(f\"\\n  Expected lift (accounting for risk): {expected_lift:.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sample Size Impact\n",
    "\n",
    "Let's see how sample size affects our confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparing different sample sizes...\\n\")\n",
    "\n",
    "sample_sizes = [1000, 2500, 5000, 10000]\n",
    "power_results = []\n",
    "\n",
    "for n in sample_sizes:\n",
    "    print(f\"Testing with {n:,} users per group...\")\n",
    "    \n",
    "    # Run smaller simulation (1000 tests is enough to estimate power)\n",
    "    temp_sims = run_monte_carlo_simulation(\n",
    "        control_rate=0.12,\n",
    "        treatment_rate=0.145,\n",
    "        n_per_group=n,\n",
    "        n_simulations=1000\n",
    "    )\n",
    "    \n",
    "    power = temp_sims['significant'].mean()\n",
    "    ci_width = temp_sims['lift'].quantile(0.975) - temp_sims['lift'].quantile(0.025)\n",
    "    \n",
    "    power_results.append({\n",
    "        'sample_size': n,\n",
    "        'power': power,\n",
    "        'ci_width': ci_width\n",
    "    })\n",
    "    \n",
    "    print(f\"  Power: {power:.1%}\")\n",
    "    print(f\"  95% CI Width: {ci_width:.2%}\\n\")\n",
    "\n",
    "power_df = pd.DataFrame(power_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample size impact\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Power vs sample size\n",
    "ax1 = axes[0]\n",
    "ax1.plot(power_df['sample_size'], power_df['power'] * 100, \n",
    "         marker='o', linewidth=3, markersize=10, color='#2ecc71')\n",
    "ax1.axhline(y=80, color='red', linestyle='--', linewidth=2, label='80% Power Target')\n",
    "ax1.set_xlabel('Sample Size per Group', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Statistical Power (%)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('How Sample Size Affects Power', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# CI width vs sample size\n",
    "ax2 = axes[1]\n",
    "ax2.plot(power_df['sample_size'], power_df['ci_width'] * 100, \n",
    "         marker='o', linewidth=3, markersize=10, color='#3498db')\n",
    "ax2.set_xlabel('Sample Size per Group', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('95% CI Width (%)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('How Sample Size Affects Precision', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Insight:\")\n",
    "print(\"  As sample size increases:\")\n",
    "print(\"    ‚úì Statistical power increases (more likely to detect real effects)\")\n",
    "print(\"    ‚úì Confidence intervals get narrower (more precise estimates)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Recommendation with Monte Carlo Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \" * 15 + \"MONTE CARLO-INFORMED DECISION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä SIMULATION RESULTS SUMMARY:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Based on 10,000 simulated A/B tests:\")\n",
    "print(f\"  ‚Ä¢ Expected lift: {simulations['lift'].mean():.2%}\")\n",
    "print(f\"  ‚Ä¢ 95% CI: [{simulations['lift'].quantile(0.025):.2%}, {simulations['lift'].quantile(0.975):.2%}]\")\n",
    "print(f\"  ‚Ä¢ Statistical power: {simulations['significant'].mean():.1%}\")\n",
    "print(f\"  ‚Ä¢ Probability of positive effect: {(simulations['lift'] > 0).mean():.1%}\")\n",
    "print(f\"  ‚Ä¢ Probability of >1% lift: {(simulations['lift'] > 0.01).mean():.1%}\")\n",
    "\n",
    "# Make recommendation\n",
    "prob_positive = (simulations['lift'] > 0).mean()\n",
    "power = simulations['significant'].mean()\n",
    "ci_lower = simulations['lift'].quantile(0.025)\n",
    "\n",
    "print(\"\\n\\nüéØ FINAL RECOMMENDATION:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if prob_positive >= 0.95 and power >= 0.8 and ci_lower > 0:\n",
    "    print(\"\\n‚úÖ STRONG RECOMMENDATION: PROCEED WITH ROLLOUT\")\n",
    "    print(\"\\nReasoning:\")\n",
    "    print(f\"  1. Very high probability ({prob_positive:.1%}) of positive effect\")\n",
    "    print(f\"  2. Adequate statistical power ({power:.1%})\")\n",
    "    print(f\"  3. 95% confident effect is positive (CI doesn't include zero)\")\n",
    "    print(\"\\nAction: Roll out the new button to all users.\")\n",
    "    \n",
    "elif prob_positive >= 0.85 and power >= 0.7:\n",
    "    print(\"\\n‚úÖ MODERATE RECOMMENDATION: PROCEED WITH CAUTION\")\n",
    "    print(\"\\nReasoning:\")\n",
    "    print(f\"  1. Good probability ({prob_positive:.1%}) of positive effect\")\n",
    "    print(f\"  2. Acceptable power ({power:.1%})\")\n",
    "    print(\"\\nAction: Gradual rollout with monitoring, or extend test for more data.\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  RECOMMENDATION: DO NOT PROCEED YET\")\n",
    "    print(\"\\nReasoning:\")\n",
    "    print(f\"  1. Probability of positive effect: {prob_positive:.1%}\")\n",
    "    print(f\"  2. Statistical power: {power:.1%}\")\n",
    "    print(\"\\nAction: Extend the test to collect more data or try a different treatment.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Takeaways\n",
    "\n",
    "### What Monte Carlo Simulation Teaches Us:\n",
    "\n",
    "1. **Quantifies Uncertainty:** We see the full range of possible outcomes, not just one test result\n",
    "2. **Validates Sample Size:** Shows whether we have enough data to make confident decisions\n",
    "3. **Estimates Risk:** Calculates probability of different scenarios (positive, negative, meaningful lift)\n",
    "4. **Alternative to Math:** Provides confidence intervals through simulation rather than formulas\n",
    "5. **Builds Intuition:** Seeing 10,000 tests helps understand statistical concepts\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "- **Finance:** Risk modeling for investment portfolios\n",
    "- **Engineering:** Reliability testing and quality control\n",
    "- **Healthcare:** Drug trial planning and analysis\n",
    "- **Business:** Revenue forecasting with uncertainty\n",
    "\n",
    "### Interview Talking Points:\n",
    "\n",
    "> \"Rather than relying on a single test, I ran 10,000 Monte Carlo simulations to understand the full distribution of possible outcomes. This revealed we have 95%+ probability of a positive effect and adequate statistical power, giving us high confidence in the recommendation.\"\n",
    "\n",
    "---\n",
    "\n",
    "*Monte Carlo simulation demonstrates advanced statistical thinking and computational skills - perfect for decision science roles at companies like Disney.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
